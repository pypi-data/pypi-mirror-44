notify_audit: false
locked: false
name: '[${environment}] disk write ops being throttled on host'
tags: ['${environment}', reactiveops]
include_tags: false
no_data_timeframe: null
silenced: {}
new_host_delay: 600
require_full_window: true
notify_no_data: false
renotify_interval: 0
evaluation_delay: 60
escalation_message: ''
query: min(last_2h):(avg:gcp.gce.instance.disk.throttled_write_ops_count{kubernetescluster:${cluster}} by {host}.rollup(avg, 300) / avg:gcp.gce.instance.disk.write_ops_count{kubernetescluster:${cluster}} by {host}.rollup(avg, 300) ) * 100 > 20
message: |
  This metric indicates disk writes are being throttled. This can result in
    - timeouts during image pulls
    - pod startup failure due to longer startups failing livenessprobe expectations
  Are one or more pods using more disk write ops than expected?
  ${notifications}
type: query alert
thresholds: {critical: 30, warning: 20, critical_recovery: 15}
timeout_h: 0
